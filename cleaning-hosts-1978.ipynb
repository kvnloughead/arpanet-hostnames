{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5459e1f9",
   "metadata": {},
   "source": [
    "# Do over\n",
    "\n",
    "Last time, we tried to use pdfminer to mine the [Arpanet Directory](https://www.google.com/books/edition/ARPANET_Directory/AHo-AQAAIAAJ?hl=en&gbpv=1&dq=arpanet+directory&printsec=frontcover) we found on Google Books. We learned some valuable things, such as that the pdf we are working with actually contains _three_ years worth of directories, starting with 1978. But we ran into [issues](https://github.com/pdfminer/pdfminer.six/issues/656) with out of place text while using pdfminer. So instead I tried the simple expedient of `ctrl + a` and it worked like a charm.\n",
    "\n",
    "I also decided it would be helpful to subdivde the full pdf even further, extracting out only the HOST ACRONYMS AND NETWORKING LIASONS table from 1978. The pdf for this table is found [here](/files/pdfs/arpanet-directory_host-acronyms-1978.pdf). The text version is [here](/files/text/hosts-1978.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b3db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ce5ac576",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_number_regex = '\\([0-9]{3}\\)[0-9]{3}-[0-9]{4}'\n",
    "page_number_regex = r'\\n[0-9]{3}\\n'\n",
    "whitespace_removal_regex = r'[^\\S\\r\\n]*([^a-zA-Z\\d\\s\\]])[^\\S\\r\\n]*' \n",
    "page_headers = ('HOST ACRONYMS\\nACRONYM ADDR . TYPE SPONSOR LIAISON and SITE ADDRESS\\n( Dec )', \n",
    "                'ARPANET DIRECTORY HOST ACRONYMS\\nNIC 46099 Dec. 1978\\nACRONYM ADDR . TYPE SPONSOR LIAISON and SITE ADDRESS\\n( Dec )\\n')\n",
    "column_names = ['acronym', 'host_address', 'type', 'sponsor', 'liason_name', 'liason_email', 'physical_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853e836",
   "metadata": {},
   "source": [
    "We start by reading the file into a string and processing it:\n",
    "\n",
    "1. Remove the first lines (up to and including the column names, which we will not use), and the last line which is a page number.\n",
    "2. Replace the headers of each page with empty strings. There are two different formats of page headers to deal with.\n",
    "3. Replace page numbers with empty strings.\n",
    "4. Remove extra whitespace from around all punctuation marks -- except for right square brackets. There are two instances of those, and the exterior whitespace is necessary.\n",
    "5. Split the string, using the phone numbers as a sepator, but keeping the separators. You can do this by enclosing the separator in a capture group.\n",
    "6. Zip the odd and even entries in this list of strings into a list of tuples, corresponding to the entries.\n",
    "\n",
    "And that'll do. Let's split off the phone numbers into a separate array or now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4ac12f37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('text/hosts-1978.txt') as hosts:\n",
    "    data = ''.join(hosts.readlines()[5:-1])\n",
    "    for s in page_headers: data = data.replace(s, '')\n",
    "    data = re.sub(page_number_regex, '', data, 0, re.DOTALL)\n",
    "    data = re.sub(whitespace_removal_regex, r'\\1', data)    # remove extra whitespace\n",
    "    phone_numbers = re.findall(phone_number_regex, data)\n",
    "    entries = re.split(phone_number_regex, data, 0, re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb937d",
   "metadata": {},
   "source": [
    "There are still a number of inconsistencies in our data. For instance, there are two occasions of square brackets that are causing issues. For instance, there are multiple occassions where there were no phone numbers. So we will need to manually split those entries, and insert corresponding empty entries in the `phone_numbers` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3572c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = re.split(r'([0-9]{5})', entries[3])\n",
    "entries[3] = ''.join(split[:2])\n",
    "entries.insert(4, ''.join(split[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30be26",
   "metadata": {},
   "source": [
    "TODO \n",
    "\n",
    "- insert missing phone number into list at index 3\n",
    "- find other missing phone_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
